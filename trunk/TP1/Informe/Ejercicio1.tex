\section{Ejercicio 1}

\subsection{Introducción}

\paragraph{}
El primer problema del presente trabajo consistió en la implementación de un algoritmo capaz de dar solución a la ecuación 
	\begin{equation} 
		b^n\ mod\ (n)
	\label{problema}
	\end{equation}
haciendo uso de alguna de las técnicas algorítmicas aprendidas hasta el momento en la materia. Asímismo, la consigna dictaba que la complejidad final del algoritmo debería ser menor a \Ode{n}.

\paragraph{}
En pos de cumplimentar lo pedido se decidió usar la técnica de \textit{Dividir \& Conquistar para desarrollar el algoritmo. Esta técnica se caracteriza principalmente en dividir la instancia de un problema en instancias más pequeñas, atacar cada una de ellas por separado y resolverlas, para finalmente juntar sus resultados y así producir el resultado final.


\subsection{Explicación}

\paragraph{}
La primera solución que se piensa casi de manera intuitiva para el problema es la de mutliplicar \textit{n} veces el número \textit{b} y luego hallar el resto de dividir ese resultado por \textit{n}. 
	\begin{equation}
		\underbrace{b.b.b \hdots b.b.b}_{n\ veces}\ mod\ (n)  = b^n\ mod\ (n)
	\label{primera_idea}		
	\end{equation}
Sin embargo, salta a la vista que la complejidad ese algoritmo es \Ode{n}, ya que se realizan \textit{n} multipicaciones y 1 división, razón por lo cual no cumple con lo pedido en la consigna. Además, puesto que ese algoritmo realizar sucesivas multipliciones de \textit{b}, cabe la posibilidad de que el valor que se va acumulando sobrepase el máximo número entero representable en la computadora produciedo así un overflow y obteniéndose en consecuencia un resultado incorrecto.

\paragraph{}
Analizando la falla del algoritmo anterior, se observa que lo que se debe evitar es calcular directamente el resultado de $b^n$ ya que ese número podría ser excesivamente grande. \\
Con esto en mente veamos una manera más conveniente de abordar el problema. Es claro, por definición de congruencia, que resover la ecuación en (\ref{problema}) equivale a hallar el \textit{x} tal que:
	\begin{equation}
		b^n\ \equiv\ x\ (n)\ , \hspace{10pt}\ con\ 0\ \leq\ x\ <\ n 
	\label{problema2}
	\end{equation}

Luego, asumamos por un momento que podemos tener gratis un k tal que:
	\begin{equation}
		b^{n/2}\ \equiv\ k\ (n)\ , \hspace{10pt}\ con\ 0\ \leq\ k\ <\ n 
	\label{divide}
	\end{equation}

Entonces, aplicando el resultado de (\ref{divide}) en (\ref{problema2}) obtenemos que:
	\begin{itemize}
		\item{
		Si \textit{n} es par:
			\begin{eqnarray}
				b^n\ \equiv\ x\ (n)\ , \hspace{10pt}\ con\ 0\ \leq\ x\ <\ n \nonumber\\
				b^{n/2}.b^{n/2}\ \equiv\ x\ (n) \nonumber\\
				k.k\ \equiv\ x\ (n) \nonumber\\
				k^2\ \equiv\ x\ (n)
			\label{recursion_par}
			\end{eqnarray}
		}
		
		\item{
		Si \textit{n} es impar par:
			\begin{eqnarray}
				b^n\ \equiv\ x\ (n)\ , \hspace{10pt}\ con\ 0\ \leq\ x\ <\ n \nonumber\\
				b.b^{n/2}.b^{n/2}\ \equiv\ x\ (n) \nonumber\\
				b.k.k\ \equiv\ x\ (n) \nonumber\\
				b.k^2\ \equiv\ x\ (n)
			\label{recursion_impar} 
			\end{eqnarray}
		}
	\end{itemize}
Luego, las expresiones resultantes en ambos casos pueden resolver de manera más simple y rápida ya que al estar acotado \textit{k} por \textit{n} el valor de $b.k^2$ es mucho menor que el de  $b^n$ y en consecuencia la operación de calcular el resto módulo \textit{n} se realiza en menor tiempo.

\paragraph{}
Volviendo un poco sobre nuestro pasos, se dijo anteriormente en (\ref{divide}) que podíamos asumir que obtener $k$ no tenía un costo computacional significativo. No obstante, esto no siempre es cierto puesto que para obtener \textit{k} es necesario calcular previamente $b^{n/2}$ el cual puede ser un número nada despreciable en lo que respecta a tamaño en memoria.\\
Si ese fuera el caso, entonces para calcular $b^{n/2}$ podemos aplicar nuevamente el procedimiento descripto con anterioridad calculando $b^{n/4}$ y usando una expresion análoga a (\ref{recursion_par}) o a (\ref{recursion_impar}) dependiendo de si $n/2$ es par o impar respectivamente. Del mismo modo se puede repetir el accionar con $b^{n/4}$ y así sucesivamente hasta reducir el exponente a 1, donde $b^1\ mod\ n$ puede calcularse en O(1) ya que \textit{b} es acotado. A partir de allí se realiza el camino inverso calculando cada uno de los restos módulo \textit{n} de las potencias de \textit{b} a partir del resto de dividir por \textit{n} a la potencia de \textit{b} calculada en el paso inmediatamente anterior, hasta dar finalmente con la solución del problema.


\subsection{Análisis de la complejidad del algoritmo}

\paragraph{}
A continuación se calculará la complejidad del algortimo implementado en la función \textit{potenciacion}, que es el que resuelve el problema que se planteo en (\ref{problema}). Dicho problema tiene por variables a $b \in \nat$ y $n \in \nat$, lo cual en términos matemáticos representa que \textit{b} y \textit{n} pueden tomar valores tan grandes como se desee puesto que $\nat$ es un conjunto infinito. Esto se ve traducido en que los parámetros del algoritmo \textit{potenciacion} sean tan grandes como uno desee. \\
Ahora bien, la consigna asegura que \textit{b} puede considerarse como un número acotado; pero aún así, \textit{n} puede seguir siendo tan grande como se quiera. Por este motivo, resulta lógico pensar que la suposición de que \textit{n} cabe perfectamente en una posicion fija de memoria no es para nada correcta. Por lo tanto, para que el análisis de complejidad del algoritmo sea lo más correcto posible se debe evaluar la complejidad de las operaciónes que realiza el algoritmo en función de la cantidad de símbolos binarios necesarios para representar el valor de cada parámetro dentro del ordenador; en particular en función del tamaño de n, ya que es el único parámetro no acotado.\\
Lo expresado en el análisis anterior conlleva a que la medición de complejidad del algortimo se efectúe mediante el \textit{modelo logarítmico} el cual precisamente mide la performance de un algoritmo a través de la suma de los costos de todas las operaciones en función del tamaño de las variables involucradas.

\paragraph{}
Los costos de las operaciones elementales en el modelo logarítmico son representadas en la siguiente tabla: \\
	\begin{center}
		\begin{tabular}{|c|c|}
			\hline
			operaciones & costo en m. logarítmico \\ 
			\hline
			& \\
			m+n & $log_2$ (m) + $log_2$ (n) \\
			& \\
			m-n & $log_2$ (m) + $log_2$ (n) \\
			& \\
			m*n & $log_2$ (m) + $log_2$ (n) \\
			& \\
			m/n & $log_2$ (m) + $log_2$ (n) \\
			& \\
			$[$ i $]$ & $log_2$ (i) \\
			& \\
			a=n & $log_2$ (n) \\
			& \\
			\hline
%		\caption{Relación entre operaciones y costo temporal en el modelo logarítmico}
		\end{tabular} 
	\end{center}

\paragraph{}
Sigue a continuación un pseudocódigo del algoritmo en cuestión en el que se detallan, para cada instrucción, su costo en el modelo logarítmico: \\

\newpage
	\incmargin{1em}
	\linesnumbered
	\restylealgo{boxed}

	\textsl{potenciacion(base : \nat,  exp: \nat,  m: \nat)}\\
	\SetKw{Orden}{Complejidad:}
		\begin{algorithm}[H]
			\Orden{T(n)}
			\BlankLine
			\textbf{var} res : \entero \\
			\BlankLine
			base $\leftarrow$ base mod m \tcp*{O($log_2$(base))}
			\BlankLine
			 \eIf{(base == 0)\tcp*{O($log_2$(base))}}
			 	{\textbf{return} base}
			{\eIf{(exp == 1)\tcp*{O($log_2$(exp))}}
				{\textbf{return} base}
			{\eIf{(exp mod 2 == 0) \tcp*{O($log_2$(exp))}}
				{\textbf{var} temp : \entero \\
				temp $\leftarrow$ potenciacion(b, exp/2, m) \tcp*{T(exp/2)}
				temp $\leftarrow$ (temp*temp) \tcp*{O($log_2(temp)^2$)}
				temp $\leftarrow$ temp mod m \tcp*{O($log_2(temp)* log_2(m)$)}
				res $\leftarrow$ temp \tcp*{O($log_2(temp)$)}}
			%else	
				{\textbf{var} temp : \entero \\
				temp $\leftarrow$ potenciacion(b, (exp-1)/2, m) \tcp*{T((exp-1)/2)}
				temp $\leftarrow$ (temp*temp) \tcp*{O($log_2(temp)^2$)}
				temp $\leftarrow$ temp mod m \tcp*{O($log_2(temp)* log_2(m)$)}
				temp $\leftarrow$ temp * base \tcp*{O($log_2(temp)* log_2(b)$)}
				temp $\leftarrow$ temp mod m \tcp*{O($log_2(temp)* log_2(m)$)}
				res $\leftarrow$ temp \tcp*{O($log_2(temp)$)}}
			}}
			\BlankLine
			\textbf{return} res
			\caption{Pseudocódigo de la función \textit{potenciación} con el costo de cada instrucción en el modelo logarítmico}
		\end{algorithm}

\paragraph{}
Como la función es recursiva, sería correcto analizar su complejidad remitiéndonos a las complejidades que se desprenden del teorema maestro. Sabemos que la forma del caso recursivo es:

\begin{equation}
	T(n) = a*T(n/b) + f(n)
\end{equation}

donde a es la cantidad de llamados recursivos, b es la cantidad de subproblemas y f(n) es el costo de cada paso sin considerar las llamadas recursivas.\\
En el caso de nuestro algoritmo, a = 1 y b = 2. Si observamos detalladamente las complejidades marcadas en el pseudocódigo, podemos ver que la complejidad mayor se da cuando se vuelve del llamado recursivo, en el momento que se eleva al cuadrado la variable $temp$. Esta variable vale como máximo m-1. Por lo tanto, $f(n) = log^{2}(n)$. Además, f(n) vale lo mismo sin importar la entrada, por lo que $f(n) \in \titade{log^{2}(n)}$

\paragraph{}
De esto se desprende entonces que para el caso de nuestro algoritmo, el modelo de complejidad recursiva esta dado por:
\begin{equation}
	T(m) = T(m/2) + f(log^{2}(n))
	\label{comprecursiva}
\end{equation}

Por otra parte, sabemos por el teorema maestro que:
\begin{equation}
	Si\ f(n) \in \titade{n^{log_{b}(a)}log^{k}(n)} \Rightarrow T(n) \in \titade{n^{log_{b}(a)}log^{k+1}(n)}
	\label{teomaestro}
\end{equation}

Si en (\ref{teomaestro}) aplicamos los valores de a y b antes mencionados, vemos que:
\begin{equation}
	f(n) \in \titade{n^{log_{2}(1)}log^{2}(n)} = \titade{log^{2}(n)}
	\label{compalgoritmo}
\end{equation}

Como $f(n) = \titade{log^{2}(n)}$, por (\ref{teomaestro} puedo decir finalmente que la cota teórica del algoritmo implementado es:
\begin{equation}
	T(n) \in \titade{log^{3}(n)}
	\label{teomaestro}
\end{equation}

\paragraph{}
Sólo resta hacer el análisis de la complejidad de acuerdo al tamaño de la entrada. El tamaño de la entrada es $E(I) = 2*log(m) > log(m)$ mientras que la complejidad de una instancia es $C(I) = log^{3}(m)$.\\
Ahora, con estos valores podemos ver que:
\begin{equation}
	C(I) \leq c' * log^{3}(m) \leq c' E(I)^{3}
\end{equation}

Entonces,
\begin{equation}
	C(I) \leq c' E(I)^{3} \Leftrightarrow C(I) \in \Ode{E(I)^{3}}
\end{equation}

\subsection{Detalles de Implementación}

\paragraph{}
Dentro de la carpeta \textit{./ej1/}, se puede encontrar el archivo ejecutable \textit{ejercicio\_1} compilado para GNU-Linux, el cual resuelve el problema anteriormente descripto. Este programa se ejecuta por consola mediante el comando \texttt{./ejercicio\_1}, y recibe como parámetro los archivos de entrada \textit{".in"} a procesar. Puede recibir tantos nombres de archivo como se desee, pero en caso de no recibir ninguno, el programa procesará el archivo \textit{Tp1Ej1.in} que se encuentra incluído dentro de la misma carpeta. \\
Una vez ejecutado, el algoritmo procesa la cola de archivos que recibió como parámertos de a uno por vez generando para cada uno de ellos dos archivos:
	\begin{itemize}
		\item{Un archivo \textit{".out"} omónimo con la solucion a la ecuación (\ref{problema}) para cada par de naturales (b, n) contenidos en el archivo de entrada. Este archivo se guarda en la misma carpeta en la que se encuentra el ejecutable \textit{ejercicio\_1}}.
		\item{Un archivo omónimo con el sufijo \textit{"\_grafico.out"}, en el cual registra para cada n el número de operaciones realizadas por el algoritmo. Este archivo se guarda en la carpeta \textit{./ej1/info graficos}, y tiene por objetivo facilitar la tarea de cargar los datos en el programa de análisis gráfico \textit{QtiPlot}}.
	\end{itemize}

\paragraph{}		
Por otra parte, en la misma carpeta, se puede hallar el archivo ejecutable \textit{input\_gen1} también compilado para GNU-Linux. Al correr este programa desde la consola mediante el comando \texttt{./input\_gen1} se despliega un menú de opciones para generar distintos tipos de archivos \textit{".in"} para ser resueltos por el ejecutable \textit{ejercicio\_1}. Una vez elegido el tipo de entrada a crear, el programa solicita que se ingrese un nombre de archivo y la cantidad de casos a generar. Acto seguido guarda el archivo generado en la carpeta \textit{./ej1/}.

\paragraph{}
Asímismo, en la carpeta \textit{./ej1/} hay un Makefile el cual permite recompilar los archivos ejecutables con tan solo ejecutar el comando \texttt{make} en la consola. Además, ejecutando el comando \texttt{make clean} se pueden eliminar los archivos ejecutables y todos los archivos de extensión \textit{".out"}.

\paragraph{}
Luego, en la carpeta \textit{./ej1/sources} se encuentran los codigos fuentes de los ejecutables antes descriptos. Los mismo están escritos en lenguaje C++ y tienen comentadas las partes relevantes para simplificar la comprensión.

\paragraph{}
Finalmente, en \textit{./ej1/} se hayan los archivos \textit{.Tp1Ej1.in} y \textit{Tp1Ej1.out} que vienen junto con en el enunciado de este Trabajo Práctico, y se haya también la carpeta \textit{./ej1/test} la cual contiene los archivos \textit{".in"} generados para probar el algortimo junto con sus correspondientes gráficos de \textit{n} vs. \textit{cantidad de operaciones}.


\subsection{Debate}
\label{Debate1}

\paragraph{}
Como primera observación de los gráficos expuestos en la sección anterior, cabe decir que la complejidad real se ajustó a la complejidad teórica, ya que en todos los casos se pudo hallar una constante $c \in\ \real$ tal que a partir de algún $n_0$ el gráfico de $c.log_2$(n) pasa a acotar superiormente a la cantidad de operaciones realizadas por el algoritmo.

\paragraph{}
En lo que respecta a la las hipótesis postuladas en la sección \ref{Resultados1}, analicemos una a una su veracidad en función de los gráficos obtenidos.\\
Se puede advertir mediante la observación del  \ref{grafico3} que se cumple la hipótesis 1, ya que para todo n la cantidad de operaciones es constante. Del mismo módo, cotejando \ref{grafico1} y \ref{grafico2} se corrobora la hipótesis 2 ya que para los \textit{n's} del caso \texttt{a} la cantidad de operaciones asciende hasta 320 aproximadamente, mientras que en el caso \texttt{b} no traspasan la barrera de las 250 operaciones.\\
En cuanto a la hipótesis 3, la comparación entre \ref{grafico1} y \ref{grafico5} no pareciera arrojar ningún dato que pudiera confirmar la suposición. Más aún, pareciera refutarla, ya que para el grueso de los \textit{n's} medidos en cada caso, el algoritmo encuentra la solución al problema en 300 operaciones aproximadamente. \\
Por último, en lo que concierne a la hipótesis 4, viendo el \ref{grafico3} se ve que para \textit{n's} en el orden de $10^9$, el algoritmo llega a realizar alrrededor de 340 operaciones; valor que sin duda supera a todas las cantidades de operaciones de los demás casos. Puede verse también que la distribución de las mediciones es la que mejor se ajusta a la curva logarítmica de entre las restantes mediciones. 


\subsection{Conclusiones}
En base analizado en la sección \ref{Debate1}, es digno de remarcar el como conclusión hecho de que la complejidad medida en la realidad se asemeja bastante a las complejidades teóricas estimadas. Asímismo, el hecho de que el número de operaciones necesarias para resolver el algoritmo crece de manera logarítmica conforme el tamaño de la entrada aumente. No obstante, en el caso en que \textit{b} sea un múltiplo de \textit{n}, el algoritmo será capaz de resolver el problema en un número constante de operaciones, aunque no así de tiempo, ya que el tiempo que demore en realizar las operaciones dependerá del tamaño de \textit{n}.
Por último, se puede concluir que el hecho de que \textit{n} sea un número primo no conlleva a un aumento significativo en la cantidad de operaciones, por lo que la complejidad real en esos casos se mantiene consistente a la complejidad teórica.


